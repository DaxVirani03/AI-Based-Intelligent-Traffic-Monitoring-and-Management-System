{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (8.3.144)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91812\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\91812\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it Before running any of the Below Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIV0Ti3Xh57q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLOv8 model...\n"
     ]
    }
   ],
   "source": [
    "# This is comment This is Basic First Code for Initializing Varibles \n",
    "#second line comment\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- USER: VERIFY YOUR PROJECT DIRECTORY ---\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/Colab_Projects/AI-Based-Intelligent-Traffic-Monitoring-and-Management-System\"\n",
    "# The name of your input video file, which should be in the 'data' subfolder\n",
    "INPUT_VIDEO_FILENAME = \"input.mp4\"\n",
    "# ---\n",
    "\n",
    "# --- USER: DEFINE YOUR LANE'S ROI HERE ---\n",
    "# Define the coordinates of YOUR lane's polygon\n",
    "ROI_POINTS = np.array([(100, 300), (800, 300), (850, 450), (50, 450)], np.int32)\n",
    "# ---\n",
    "\n",
    "# Construct full paths for video files\n",
    "input_video_path = os.path.join(PROJECT_DIR, 'data', INPUT_VIDEO_FILENAME)\n",
    "output_video_path = os.path.join(PROJECT_DIR, 'output', 'output_vehicle_count.mp4')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(os.path.join(PROJECT_DIR, 'output'), exist_ok=True)\n",
    "\n",
    "# Change the current working directory to the project folder\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "# Load the pre-trained YOLOv8 model\n",
    "print(\"Loading YOLOv8 model...\")\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# COCO class IDs for vehicles (car, motorcycle, bus, truck)\n",
    "VEHICLE_CLASS_IDS = [2, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Processing especially for google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMMAi5naiBt-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting live detection... Press 'q' to quit.\n",
      "\n",
      "0: 480x640 4 persons, 271.7ms\n",
      "Speed: 13.7ms preprocess, 271.7ms inference, 21.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 424.8ms\n",
      "Speed: 13.4ms preprocess, 424.8ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 198.6ms\n",
      "Speed: 10.3ms preprocess, 198.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 243.6ms\n",
      "Speed: 7.5ms preprocess, 243.6ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 201.2ms\n",
      "Speed: 1.8ms preprocess, 201.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 213.1ms\n",
      "Speed: 1.9ms preprocess, 213.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 152.0ms\n",
      "Speed: 3.9ms preprocess, 152.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 171.7ms\n",
      "Speed: 2.4ms preprocess, 171.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 191.9ms\n",
      "Speed: 4.7ms preprocess, 191.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 208.2ms\n",
      "Speed: 13.2ms preprocess, 208.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 192.5ms\n",
      "Speed: 2.0ms preprocess, 192.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 141.1ms\n",
      "Speed: 6.0ms preprocess, 141.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 147.7ms\n",
      "Speed: 1.6ms preprocess, 147.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 157.3ms\n",
      "Speed: 2.3ms preprocess, 157.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 254.7ms\n",
      "Speed: 3.6ms preprocess, 254.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 laptop, 162.1ms\n",
      "Speed: 1.9ms preprocess, 162.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 177.5ms\n",
      "Speed: 6.5ms preprocess, 177.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 146.5ms\n",
      "Speed: 4.7ms preprocess, 146.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 157.9ms\n",
      "Speed: 1.9ms preprocess, 157.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 149.0ms\n",
      "Speed: 2.6ms preprocess, 149.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 159.4ms\n",
      "Speed: 1.9ms preprocess, 159.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 145.9ms\n",
      "Speed: 3.1ms preprocess, 145.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 174.3ms\n",
      "Speed: 3.3ms preprocess, 174.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 153.7ms\n",
      "Speed: 1.8ms preprocess, 153.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 173.5ms\n",
      "Speed: 1.9ms preprocess, 173.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 147.0ms\n",
      "Speed: 2.2ms preprocess, 147.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 161.2ms\n",
      "Speed: 2.4ms preprocess, 161.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 168.2ms\n",
      "Speed: 2.0ms preprocess, 168.2ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 169.7ms\n",
      "Speed: 4.4ms preprocess, 169.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 156.9ms\n",
      "Speed: 2.5ms preprocess, 156.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 138.7ms\n",
      "Speed: 2.4ms preprocess, 138.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 145.8ms\n",
      "Speed: 2.6ms preprocess, 145.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 146.1ms\n",
      "Speed: 2.4ms preprocess, 146.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 159.7ms\n",
      "Speed: 4.2ms preprocess, 159.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 145.6ms\n",
      "Speed: 2.4ms preprocess, 145.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 150.5ms\n",
      "Speed: 2.2ms preprocess, 150.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 152.3ms\n",
      "Speed: 6.0ms preprocess, 152.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 146.5ms\n",
      "Speed: 1.9ms preprocess, 146.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 152.5ms\n",
      "Speed: 1.8ms preprocess, 152.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 139.8ms\n",
      "Speed: 2.2ms preprocess, 139.8ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 laptop, 191.2ms\n",
      "Speed: 7.5ms preprocess, 191.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 144.9ms\n",
      "Speed: 2.2ms preprocess, 144.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 159.9ms\n",
      "Speed: 2.2ms preprocess, 159.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 140.4ms\n",
      "Speed: 8.0ms preprocess, 140.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 135.9ms\n",
      "Speed: 3.1ms preprocess, 135.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 181.9ms\n",
      "Speed: 6.0ms preprocess, 181.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 157.4ms\n",
      "Speed: 2.6ms preprocess, 157.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 141.7ms\n",
      "Speed: 4.5ms preprocess, 141.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 140.5ms\n",
      "Speed: 4.2ms preprocess, 140.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 152.1ms\n",
      "Speed: 2.6ms preprocess, 152.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 150.3ms\n",
      "Speed: 2.8ms preprocess, 150.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 148.1ms\n",
      "Speed: 3.0ms preprocess, 148.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 203.4ms\n",
      "Speed: 7.8ms preprocess, 203.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 162.1ms\n",
      "Speed: 2.8ms preprocess, 162.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 259.3ms\n",
      "Speed: 2.7ms preprocess, 259.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 159.7ms\n",
      "Speed: 3.1ms preprocess, 159.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 158.5ms\n",
      "Speed: 3.4ms preprocess, 158.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 167.2ms\n",
      "Speed: 2.8ms preprocess, 167.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 129.5ms\n",
      "Speed: 2.7ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 160.5ms\n",
      "Speed: 5.0ms preprocess, 160.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 157.7ms\n",
      "Speed: 3.7ms preprocess, 157.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 152.4ms\n",
      "Speed: 2.1ms preprocess, 152.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 160.0ms\n",
      "Speed: 2.3ms preprocess, 160.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 163.7ms\n",
      "Speed: 2.2ms preprocess, 163.7ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 153.4ms\n",
      "Speed: 2.3ms preprocess, 153.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 140.3ms\n",
      "Speed: 2.9ms preprocess, 140.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 198.0ms\n",
      "Speed: 2.8ms preprocess, 198.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 268.4ms\n",
      "Speed: 2.8ms preprocess, 268.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 261.6ms\n",
      "Speed: 8.3ms preprocess, 261.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 365.9ms\n",
      "Speed: 2.2ms preprocess, 365.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 159.8ms\n",
      "Speed: 5.7ms preprocess, 159.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 laptops, 232.4ms\n",
      "Speed: 6.0ms preprocess, 232.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 laptops, 208.8ms\n",
      "Speed: 7.9ms preprocess, 208.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 2 laptops, 139.3ms\n",
      "Speed: 1.9ms preprocess, 139.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 1 laptop, 158.9ms\n",
      "Speed: 2.2ms preprocess, 158.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 laptop, 155.3ms\n",
      "Speed: 4.3ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 laptop, 164.9ms\n",
      "Speed: 3.3ms preprocess, 164.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 2 laptops, 193.0ms\n",
      "Speed: 2.6ms preprocess, 193.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 2 laptops, 204.5ms\n",
      "Speed: 6.9ms preprocess, 204.5ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 toilet, 212.8ms\n",
      "Speed: 2.6ms preprocess, 212.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 laptop, 184.4ms\n",
      "Speed: 5.7ms preprocess, 184.4ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 183.6ms\n",
      "Speed: 2.9ms preprocess, 183.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 223.0ms\n",
      "Speed: 4.0ms preprocess, 223.0ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 434.7ms\n",
      "Speed: 6.8ms preprocess, 434.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 265.3ms\n",
      "Speed: 4.8ms preprocess, 265.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 349.5ms\n",
      "Speed: 7.2ms preprocess, 349.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 334.7ms\n",
      "Speed: 5.4ms preprocess, 334.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 444.9ms\n",
      "Speed: 8.0ms preprocess, 444.9ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 237.5ms\n",
      "Speed: 5.7ms preprocess, 237.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 205.6ms\n",
      "Speed: 7.3ms preprocess, 205.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 351.6ms\n",
      "Speed: 5.8ms preprocess, 351.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 215.3ms\n",
      "Speed: 2.9ms preprocess, 215.3ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 198.7ms\n",
      "Speed: 2.6ms preprocess, 198.7ms inference, 6.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 191.9ms\n",
      "Speed: 3.9ms preprocess, 191.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 176.5ms\n",
      "Speed: 5.1ms preprocess, 176.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 192.5ms\n",
      "Speed: 2.7ms preprocess, 192.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 283.5ms\n",
      "Speed: 2.5ms preprocess, 283.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 219.1ms\n",
      "Speed: 6.5ms preprocess, 219.1ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 198.7ms\n",
      "Speed: 2.8ms preprocess, 198.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 209.0ms\n",
      "Speed: 6.0ms preprocess, 209.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 354.7ms\n",
      "Speed: 9.8ms preprocess, 354.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 297.9ms\n",
      "Speed: 19.7ms preprocess, 297.9ms inference, 9.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 207.3ms\n",
      "Speed: 8.1ms preprocess, 207.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 toilet, 257.0ms\n",
      "Speed: 5.7ms preprocess, 257.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 196.5ms\n",
      "Speed: 5.0ms preprocess, 196.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 210.7ms\n",
      "Speed: 3.9ms preprocess, 210.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 196.9ms\n",
      "Speed: 7.1ms preprocess, 196.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 toilet, 193.8ms\n",
      "Speed: 5.0ms preprocess, 193.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 285.9ms\n",
      "Speed: 7.0ms preprocess, 285.9ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 243.8ms\n",
      "Speed: 6.8ms preprocess, 243.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 164.3ms\n",
      "Speed: 3.0ms preprocess, 164.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 187.7ms\n",
      "Speed: 5.0ms preprocess, 187.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 143.5ms\n",
      "Speed: 2.0ms preprocess, 143.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 175.1ms\n",
      "Speed: 3.2ms preprocess, 175.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 165.6ms\n",
      "Speed: 2.2ms preprocess, 165.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 141.0ms\n",
      "Speed: 5.7ms preprocess, 141.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 174.1ms\n",
      "Speed: 2.2ms preprocess, 174.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 164.2ms\n",
      "Speed: 2.3ms preprocess, 164.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 159.9ms\n",
      "Speed: 2.1ms preprocess, 159.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 160.6ms\n",
      "Speed: 7.3ms preprocess, 160.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 168.5ms\n",
      "Speed: 4.5ms preprocess, 168.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 155.5ms\n",
      "Speed: 4.3ms preprocess, 155.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 145.7ms\n",
      "Speed: 2.0ms preprocess, 145.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 166.7ms\n",
      "Speed: 2.2ms preprocess, 166.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 177.7ms\n",
      "Speed: 2.9ms preprocess, 177.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 137.9ms\n",
      "Speed: 2.4ms preprocess, 137.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 133.1ms\n",
      "Speed: 2.7ms preprocess, 133.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 158.0ms\n",
      "Speed: 2.8ms preprocess, 158.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 166.1ms\n",
      "Speed: 2.5ms preprocess, 166.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 164.5ms\n",
      "Speed: 2.6ms preprocess, 164.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 184.2ms\n",
      "Speed: 3.6ms preprocess, 184.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 toilet, 183.6ms\n",
      "Speed: 8.4ms preprocess, 183.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 192.0ms\n",
      "Speed: 4.3ms preprocess, 192.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 161.5ms\n",
      "Speed: 7.2ms preprocess, 161.5ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 203.4ms\n",
      "Speed: 6.4ms preprocess, 203.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 208.8ms\n",
      "Speed: 2.2ms preprocess, 208.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 143.8ms\n",
      "Speed: 2.7ms preprocess, 143.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 150.2ms\n",
      "Speed: 2.0ms preprocess, 150.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 165.1ms\n",
      "Speed: 2.3ms preprocess, 165.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 151.9ms\n",
      "Speed: 2.2ms preprocess, 151.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 163.4ms\n",
      "Speed: 2.3ms preprocess, 163.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 toilet, 181.8ms\n",
      "Speed: 2.4ms preprocess, 181.8ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 153.4ms\n",
      "Speed: 2.6ms preprocess, 153.4ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 167.4ms\n",
      "Speed: 6.0ms preprocess, 167.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 toilet, 184.8ms\n",
      "Speed: 4.5ms preprocess, 184.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 146.7ms\n",
      "Speed: 2.3ms preprocess, 146.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 181.1ms\n",
      "Speed: 5.5ms preprocess, 181.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 toilet, 157.6ms\n",
      "Speed: 8.3ms preprocess, 157.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 140.1ms\n",
      "Speed: 6.3ms preprocess, 140.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 160.7ms\n",
      "Speed: 2.4ms preprocess, 160.7ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 156.0ms\n",
      "Speed: 2.6ms preprocess, 156.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 272.4ms\n",
      "Speed: 2.4ms preprocess, 272.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 211.5ms\n",
      "Speed: 6.0ms preprocess, 211.5ms inference, 5.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 140.9ms\n",
      "Speed: 2.3ms preprocess, 140.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 182.5ms\n",
      "Speed: 15.7ms preprocess, 182.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 toilet, 208.5ms\n",
      "Speed: 1.8ms preprocess, 208.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 239.4ms\n",
      "Speed: 11.8ms preprocess, 239.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 222.4ms\n",
      "Speed: 4.6ms preprocess, 222.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 toilet, 205.4ms\n",
      "Speed: 4.1ms preprocess, 205.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 167.0ms\n",
      "Speed: 2.7ms preprocess, 167.0ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 181.8ms\n",
      "Speed: 3.1ms preprocess, 181.8ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 147.1ms\n",
      "Speed: 4.1ms preprocess, 147.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 193.3ms\n",
      "Speed: 5.5ms preprocess, 193.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 toilet, 136.4ms\n",
      "Speed: 2.9ms preprocess, 136.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 114.9ms\n",
      "Speed: 2.2ms preprocess, 114.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 118.1ms\n",
      "Speed: 1.9ms preprocess, 118.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 112.4ms\n",
      "Speed: 2.1ms preprocess, 112.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 134.4ms\n",
      "Speed: 3.8ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 116.7ms\n",
      "Speed: 2.5ms preprocess, 116.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 toilet, 109.3ms\n",
      "Speed: 2.8ms preprocess, 109.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 132.3ms\n",
      "Speed: 2.3ms preprocess, 132.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 121.6ms\n",
      "Speed: 2.0ms preprocess, 121.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 112.1ms\n",
      "Speed: 2.6ms preprocess, 112.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 laptops, 113.5ms\n",
      "Speed: 3.8ms preprocess, 113.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 laptop, 133.5ms\n",
      "Speed: 1.8ms preprocess, 133.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 134.3ms\n",
      "Speed: 2.1ms preprocess, 134.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 137.4ms\n",
      "Speed: 2.8ms preprocess, 137.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 1 laptop, 144.2ms\n",
      "Speed: 3.3ms preprocess, 144.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 laptop, 136.6ms\n",
      "Speed: 3.1ms preprocess, 136.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 2 laptops, 135.9ms\n",
      "Speed: 2.9ms preprocess, 135.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 laptops, 135.0ms\n",
      "Speed: 3.3ms preprocess, 135.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 laptops, 115.9ms\n",
      "Speed: 3.1ms preprocess, 115.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 laptop, 112.3ms\n",
      "Speed: 2.9ms preprocess, 112.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 laptop, 111.2ms\n",
      "Speed: 2.2ms preprocess, 111.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 bird, 1 laptop, 118.4ms\n",
      "Speed: 2.7ms preprocess, 118.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 1 laptop, 118.9ms\n",
      "Speed: 2.5ms preprocess, 118.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 laptop, 102.5ms\n",
      "Speed: 2.5ms preprocess, 102.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 1 laptop, 118.2ms\n",
      "Speed: 2.5ms preprocess, 118.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "🛑 Releasing resources...\n"
     ]
    }
   ],
   "source": [
    "# Open the input video file\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video at {input_video_path}\")\n",
    "else:\n",
    "    # Get video properties for the output file\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    print(f\"Processing video: {INPUT_VIDEO_FILENAME}...\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break # End of video\n",
    "\n",
    "        # This check prevents errors if a frame is corrupted\n",
    "        if frame.shape[1] != frame_width or frame.shape[0] != frame_height:\n",
    "            frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "        # Reset counter for each frame\n",
    "        vehicle_count = 0\n",
    "\n",
    "        # Draw the ROI polygon once per frame\n",
    "        cv2.polylines(frame, [ROI_POINTS], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "        # Run YOLO detection\n",
    "        results = model(frame)\n",
    "\n",
    "        # Process detections\n",
    "        for box in results[0].boxes:\n",
    "            if int(box.cls) in VEHICLE_CLASS_IDS:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "                if cv2.pointPolygonTest(ROI_POINTS, (center_x, center_y), False) >= 0:\n",
    "                    vehicle_count += 1\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Write the final count and the frame to the output video\n",
    "        cv2.putText(frame, f\"Vehicles in Lane: {vehicle_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        out.write(frame)\n",
    "\n",
    "finally:\n",
    "    # This ensures files are closed properly even if an error occurs\n",
    "    print(\"Processing complete. Releasing resources.\")\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Through Web Cam on Local Pc \"Live\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Load YOLO model ---\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# --- ROI (adjust to your camera view) ---\n",
    "ROI_POINTS = np.array([(150, 100), (600, 100), (600, 400), (150, 400)], np.int32)\n",
    "\n",
    "# Vehicle class IDs (car=2, motorcycle=3, bus=5, truck=7)\n",
    "VEHICLE_CLASS_IDS = [2, 3, 5, 7]\n",
    "\n",
    "# --- Open webcam ---\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # try without CAP_DSHOW if on Linux/Mac\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"🚀 Starting live detection... Press 'q' to quit.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            print(\"❌ Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Reset vehicle counter\n",
    "        vehicle_count = 0\n",
    "\n",
    "        # Draw ROI\n",
    "        cv2.polylines(frame, [ROI_POINTS], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "\n",
    "        # Run YOLO detection\n",
    "        results = model(frame)\n",
    "\n",
    "        for box in results[0].boxes:\n",
    "            cls_id = int(box.cls)\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            if cls_id in VEHICLE_CLASS_IDS and conf > 0.5:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "                if cv2.pointPolygonTest(ROI_POINTS, (center_x, center_y), False) >= 0:\n",
    "                    vehicle_count += 1\n",
    "                    label = f\"{model.names[cls_id]} {conf:.2f}\"\n",
    "\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Display count\n",
    "        cv2.putText(frame, f\"Vehicles in ROI: {vehicle_count}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Show live feed\n",
    "        cv2.imshow(\"YOLO Vehicle Detection - Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    print(\"🛑 Releasing resources...\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJoxAfG4MrncbHemfXyQ/1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
